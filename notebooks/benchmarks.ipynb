{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e684cf2-c6b8-494c-933a-21249c342e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Function Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddb5fdf4-8201-4106-af77-781069f28d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def force_unicode(s):\n",
    "    return str(s)\n",
    "\n",
    "\n",
    "def normalize_unicode(s):\n",
    "    return unicodedata.normalize(\"NFC\", s)\n",
    "\n",
    "\n",
    "class BagError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class BagValidationError(BagError):\n",
    "    def __init__(self, message, details=None):\n",
    "        super(BagValidationError, self).__init__()\n",
    "\n",
    "        if details is None:\n",
    "            details = []\n",
    "\n",
    "        self.message = message\n",
    "        self.details = details\n",
    "\n",
    "    def __str__(self):\n",
    "        if len(self.details) > 0:\n",
    "            details = \"; \".join([force_unicode(e) for e in self.details])\n",
    "            return \"%s: %s\" % (self.message, details)\n",
    "        return self.message\n",
    "\n",
    "\n",
    "class ManifestErrorDetail(BagError):\n",
    "    def __init__(self, path):\n",
    "        super(ManifestErrorDetail, self).__init__()\n",
    "\n",
    "        self.path = path\n",
    "\n",
    "\n",
    "class ChecksumMismatch(ManifestErrorDetail):\n",
    "    def __init__(self, path, algorithm=None, expected=None, found=None):\n",
    "        super(ChecksumMismatch, self).__init__(path)\n",
    "\n",
    "        self.path = path\n",
    "        self.algorithm = algorithm\n",
    "        self.expected = expected\n",
    "        self.found = found\n",
    "\n",
    "    def __str__(self):\n",
    "        return _(\n",
    "            '%(path)s %(algorithm)s validation failed: expected=\"%(expected)s\" found=\"%(found)s\"'\n",
    "        ) % {\n",
    "            \"path\": force_unicode(self.path),\n",
    "            \"algorithm\": self.algorithm,\n",
    "            \"expected\": self.expected,\n",
    "            \"found\": self.found,\n",
    "        }\n",
    "\n",
    "\n",
    "class FileMissing(ManifestErrorDetail):\n",
    "    def __str__(self):\n",
    "        return _(\n",
    "            \"%s exists in manifest but was not found on filesystem\"\n",
    "        ) % force_unicode(self.path)\n",
    "\n",
    "\n",
    "class UnexpectedFile(ManifestErrorDetail):\n",
    "    def __str__(self):\n",
    "        return _(\"%s exists on filesystem but is not in the manifest\") % self.path\n",
    "\n",
    "\n",
    "class FileNormalizationConflict(BagError):\n",
    "    \"\"\"\n",
    "    Exception raised when two files differ only in normalization and thus\n",
    "    are not safely portable\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_a, file_b):\n",
    "        super(FileNormalizationConflict, self).__init__()\n",
    "\n",
    "        self.file_a = file_a\n",
    "        self.file_b = file_b\n",
    "\n",
    "    def __str__(self):\n",
    "        return _(\n",
    "            'Unicode normalization conflict for file \"%(file_a)s\" and \"%(file_b)s\"'\n",
    "        ) % {\"file_a\": self.file_a, \"file_b\": self.file_b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9f13919-363b-4295-b529-d07ac19ba0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filenames.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "241c2644-3a4b-4139-9729-427187c0eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "075a3bb5-9ed3-4c67-ac3c-6913f9cbe4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_filename_nochain(s):\n",
    "    s = s.replace(\"\\r\", \"%0D\")\n",
    "    s = s.replace(\"\\n\", \"%0A\")\n",
    "    return s\n",
    "\n",
    "\n",
    "def _decode_filename_regex(s):\n",
    "    s = re.sub(r\"%0D\", \"\\r\", s, re.IGNORECASE)\n",
    "    s = re.sub(r\"%0A\", \"\\n\", s, re.IGNORECASE)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cff9c79c-e22a-4e34-adc9-277a2787b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_filename_chain(s):\n",
    "    return s.replace(\"\\r\", \"%0D\").replace(\"\\n\", \"%0A\")\n",
    "\n",
    "def _decode_filename_replace(s):\n",
    "    return s.replace(\"%0D\", \"\\r\").replace(\"%0A\", \"\\n\").replace(\"%0d\", \"\\r\").replace(\"%0a\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfe3c39e-0494-4ddf-95a2-2297f7d8b51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.8 ns ± 0.599 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "_encode_filename_nochain('some_test_filename_98239018.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ac27d2b-4c2c-4b41-8dcf-480339797ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.2 ns ± 0.284 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "_encode_filename_chain('some_test_filename_98239018.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbc87f0a-25ae-49e3-b217-afcd2d2b423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528 ns ± 6.5 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "_decode_filename_regex('some_test_filename_98239018.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "120ef084-4878-4502-b91d-174c424fb930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 ns ± 0.926 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_decode_filename_replace('some_test_filename_98239018.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98ef7109-22aa-4d3c-aaa0-44221495ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hashing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33e5305b-f2d9-4b93-a505-b2aeb460a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb07bebc-fbfa-40a6-89f7-a1f14ebcdaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_file_hashes_old(full_path, f_hashers):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of (algorithm, hexdigest) values for the provided\n",
    "    filename\n",
    "    \"\"\"\n",
    "    LOGGER.info(_(\"Verifying checksum for file %s\"), full_path)\n",
    "\n",
    "    try:\n",
    "        with open(full_path, \"rb\") as f:\n",
    "            while True:\n",
    "                block = f.read(HASH_BLOCK_SIZE)\n",
    "                if not block:\n",
    "                    break\n",
    "                for i in f_hashers.values():\n",
    "                    i.update(block)\n",
    "    except (OSError, IOError) as e:\n",
    "        raise BagValidationError(\n",
    "            _(\"Could not read %(filename)s: %(error)s\")\n",
    "            % {\"filename\": full_path, \"error\": force_unicode(e)}\n",
    "        )\n",
    "\n",
    "    return dict((alg, h.hexdigest()) for alg, h in f_hashers.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eafbd8bc-d269-4fc0-a58b-3ebe3eb25846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_file_hashes_new(full_path, f_hashers):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of (algorithm, hexdigest) values for the provided\n",
    "    filename\n",
    "    \"\"\"\n",
    "    LOGGER.info(_(\"Verifying checksum for file %s\"), full_path)\n",
    "    \n",
    "    hashers = list(f_hashers.values())  # Get hashers once before the loop\n",
    "\n",
    "    try:\n",
    "        with open(full_path, \"rb\") as f:\n",
    "            for block in iter(lambda: f.read(HASH_BLOCK_SIZE), b''):\n",
    "                for hasher in hashers:\n",
    "                    hasher.update(block)\n",
    "    except (OSError, IOError) as e:\n",
    "        raise BagValidationError(\n",
    "            _(\"Could not read %(filename)s: %(error)s\")\n",
    "            % {\"filename\": full_path, \"error\": force_unicode(e)}\n",
    "        )\n",
    "\n",
    "    return {alg: hasher.hexdigest() for alg, hasher in f_hashers.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4dedb-db8b-4e90-a6ad-27aa76a9737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger('notebook_test')\n",
    "hashes = ['sha512']\n",
    "algorithms\n",
    "f_hashers = dict((alg, hashlib.new(alg)) for alg in hashes if alg in algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a928c5-1c04-4ca2-bc27-762763c81291",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "_calculate_file_hashes_old(full_path, f_hashers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
